# LlamaStack Sever and Client 

### Prerequisites 
1. install ollama https://ollama.com/
2. install uv https://docs.astral.sh/uv/
3. install docker or podman 

### Run 
1. `make run_llamastack_server` (llama stack )
2. in a seperate termianl `make run_llamastack_client` (llama stack )
3. in a seperate terminal `make run_mcp`
4. in a seperate terminal `make run_agent_simple1`

